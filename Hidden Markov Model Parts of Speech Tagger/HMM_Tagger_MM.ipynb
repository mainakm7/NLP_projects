{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Part of Speech Tagging with Hidden Markov Models \n",
    "---\n",
    "### Introduction\n",
    "\n",
    "Part of speech tagging is the process of determining the syntactic category of a word from the words in its surrounding context. It is often used to help disambiguate natural language phrases because it can be done quickly with high accuracy. Tagging can be used for many NLP tasks like determining correct pronunciation during speech synthesis (for example, _dis_-count as a noun vs dis-_count_ as a verb), for information retrieval, and for word sense disambiguation.\n",
    "\n",
    "In this notebook, you'll use the [Pomegranate](http://pomegranate.readthedocs.io/) library to build a hidden Markov model for part of speech tagging using a \"universal\" tagset. Hidden Markov models have been able to achieve [>96% tag accuracy with larger tagsets on realistic text corpora](http://www.coli.uni-saarland.de/~thorsten/publications/Brants-ANLP00.pdf). Hidden Markov models have also been used for speech recognition and speech generation, machine translation, gene recognition for bioinformatics, and human gesture recognition for computer vision, and more. \n",
    "\n",
    "![](_post-hmm.png)\n",
    "\n",
    "The notebook already contains some code to get you started. You only need to add some new functionality in the areas indicated to complete the project; you will not need to modify the included code beyond what is requested. Sections that begin with **'IMPLEMENTATION'** in the header indicate that you must provide code in the block that follows. Instructions will be provided for each section, and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "**Note:** Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You must then **export the notebook** by running the last cell in the notebook, or by using the menu above and navigating to **File -> Download as -> HTML (.html)** Your submissions should include both the `html` and `ipynb` files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "**Note:** Code and Markdown cells can be executed using the `Shift + Enter` keyboard shortcut. Markdown cells can be edited by double-clicking the cell to enter edit mode.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Road Ahead\n",
    "You must complete Steps 1-3 below to pass the project. The section on Step 4 includes references & resources you can use to further explore HMM taggers.\n",
    "\n",
    "- [Step 1](#Step-1:-Read-and-preprocess-the-dataset): Review the provided interface to load and access the text corpus\n",
    "- [Step 2](#Step-2:-Build-a-Most-Frequent-Class-tagger): Build a Most Frequent Class tagger to use as a baseline\n",
    "- [Step 3](#Step-3:-Build-an-HMM-tagger): Build an HMM Part of Speech tagger and compare to the MFC baseline\n",
    "- [Step 4](#Step-4:-[Optional]-Improving-model-performance): (Optional) Improve the HMM tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport helpers, tests\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import show_model, Dataset\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences in the corpus.\n",
      "There are 45872 sentences in the training set.\n",
      "There are 11468 sentences in the testing set.\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"tags-universal.txt\", \"brown-universal.txt\", train_test_split=0.8)\n",
    "\n",
    "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
    "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
    "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences\n",
    "\n",
    "`Dataset.sentences` is a dictionary of all sentences in the training corpus, each keyed to a unique sentence identifier. Each `Sentence` is itself an object with two attributes: a tuple of the words in the sentence named `words` and a tuple of the tag corresponding to each word named `tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: b100-38532\n",
      "words:\n",
      "\t('Perhaps', 'it', 'was', 'right', ';', ';')\n",
      "tags:\n",
      "\t('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"
     ]
    }
   ],
   "source": [
    "key = 'b100-38532'\n",
    "print(\"Sentence: {}\".format(key))\n",
    "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
    "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
      "There are 928458 samples of 50536 unique words in the training set.\n",
      "There are 232734 samples of 25112 unique words in the testing set.\n",
      "There are 5521 words in the test set that are missing in the training set.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
    "      .format(data.N, len(data.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the training set.\"\n",
    "      .format(data.training_set.N, len(data.training_set.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the testing set.\"\n",
    "      .format(data.testing_set.N, len(data.testing_set.vocab)))\n",
    "print(\"There are {} words in the test set that are missing in the training set.\"\n",
    "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing word and tag Sequences\n",
    "The `Dataset.X` and `Dataset.Y` attributes provide access to ordered collections of matching word and tag sequences for each sentence in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
      "\n",
      "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
      "\n",
      "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accessing words with Dataset.X and tags with Dataset.Y \n",
    "for i in range(2):    \n",
    "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
    "    print()\n",
    "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing (word, tag) Samples\n",
    "The `Dataset.stream()` method returns an iterator that chains together every pair of (word, tag) entries across all sentences in the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stream (word, tag) pairs:\n",
      "\n",
      "\t ('Mr.', 'NOUN')\n",
      "\t ('Podger', 'NOUN')\n",
      "\t ('had', 'VERB')\n",
      "\t ('thanked', 'VERB')\n",
      "\t ('him', 'PRON')\n",
      "\t ('gravely', 'ADV')\n",
      "\t (',', '.')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStream (word, tag) pairs:\\n\")\n",
    "for i, pair in enumerate(data.stream()):\n",
    "    print(\"\\t\", pair)\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build a Most Frequent Class tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pair_counts(sequences_A, sequences_B):\n",
    "    \"\"\"Returns a dictionary keyed to each unique value in the first sequence list\n",
    "    that counts the number of occurrences of the corresponding value from the\n",
    "    second sequences list.\n",
    "    \n",
    "    For example, if sequences_A is tags and sequences_B is the corresponding\n",
    "    words, then if 1244 sequences contain the word \"time\" tagged as a NOUN, then\n",
    "    function returns a dictionary such that pair_counts[NOUN][time] == 1244\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    dictu = defaultdict(dict)\n",
    "    for tag, word in zip(sequences_A, sequences_B):\n",
    "        \n",
    "        \n",
    "        if word not in dictu[tag].keys():\n",
    "            dictu[tag][word] = 0\n",
    "        dictu[tag][word] += 1\n",
    "    \n",
    "    return dictu\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "alltags,allwords = [],[]\n",
    "# for i in range(len(data)):\n",
    "#     for tag,word in zip(data.Y[i],data.X[i]):\n",
    "#         alltags.append(tag)\n",
    "#         allwords.append(word)\n",
    "\n",
    "for pair in data.stream():\n",
    "    alltags.append(pair[1])\n",
    "    allwords.append(pair[0])\n",
    "        \n",
    "\n",
    "\n",
    "emission_counts = pair_counts(alltags,allwords)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NOUN', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADP', 'DET', 'PRT', 'ADJ', 'X', 'NUM'])\n"
     ]
    }
   ],
   "source": [
    "print(emission_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your MFC tagger has all the correct words!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
    "from collections import namedtuple\n",
    "\n",
    "FakeState = namedtuple(\"FakeState\", \"name\")\n",
    "\n",
    "class MFCTagger:\n",
    "    \n",
    "    missing = FakeState(name=\"<MISSING>\")\n",
    "    \n",
    "    def __init__(self, table):\n",
    "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
    "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
    "        \n",
    "    def viterbi(self, seq):\n",
    "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_tags,train_words = [],[]\n",
    "\n",
    "for pair in data.training_set.stream():\n",
    "    train_tags.append(pair[1])\n",
    "    train_words.append(pair[0])\n",
    "    \n",
    "    \n",
    "word_counts = pair_counts(train_tags,train_words)\n",
    "\n",
    "mfc_table = {}\n",
    "word_max = {}\n",
    "for tag in word_counts.keys():\n",
    "    for word in word_counts[tag].keys():\n",
    "        if word not in word_max:\n",
    "            word_max[word] = 0\n",
    "            \n",
    "        if word_counts[tag][word]>word_max[word]:\n",
    "                word_max[word] = word_counts[tag][word]\n",
    "                mfc_table[word] = tag\n",
    "\n",
    "\n",
    "\n",
    "mfc_model = MFCTagger(mfc_table) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with a Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unknown(sequence):\n",
    "    \"\"\"Returns a copy of the input sequence where each unknown word is replaced\n",
    "    by the literal string value 'nan'. \n",
    "    \"\"\"\n",
    "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding(X, model):\n",
    "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
    "    _, state_path = model.viterbi(replace_unknown(X))\n",
    "    return [state[1].name for state in state_path[1:-1]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Decoding Sequences with MFC Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', '<MISSING>', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADV', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Accuracy\n",
    "\n",
    "The function below will evaluate the accuracy of the MFC tagger on the collection of all sentences from a text corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, model):\n",
    "    \"\"\"Calculates the prediction accuracy by using the model to decode each sequence\n",
    "    in the input X and comparing the prediction with the true labels in Y.\n",
    "    \n",
    "    The X should be an array whose first dimension is the number of sentences to test,\n",
    "    and each element of the array should be an iterable of the words in the sequence.\n",
    "    The arrays X and Y should have the exact same shape.\n",
    "    \n",
    "    X = [(\"See\", \"Spot\", \"run\"), (\"Run\", \"Spot\", \"run\", \"fast\"), ...]\n",
    "    Y = [(), (), ...]\n",
    "    \"\"\"\n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "        \n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding(observations, model)\n",
    "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "    return correct / total_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the accuracy of the MFC tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy mfc_model: 95.72%\n",
      "testing accuracy mfc_model: 93.02%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your MFC tagger accuracy looks correct!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
    "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
    "\n",
    "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
    "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build an HMM tagger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Counts\n",
    "\n",
    "Function below estimates the co-occurrence frequency of each symbol over all of the input sequences. The unigram probabilities in our HMM model are estimated from the formula below, where N is the total number of samples in the input.\n",
    "\n",
    "$$P(tag_1) = \\frac{C(tag_1)}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your tag unigrams look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unigram_counts(sequences):\n",
    "    \"\"\"Returns a dictionary keyed to each unique value in the input sequence list that\n",
    "    counts the number of occurrences of the value in the sequences list. The sequences\n",
    "    collection should be a 2-dimensional array.\n",
    "    \n",
    "    For example, if the tag NOUN appears 275558 times over all the input sequences,\n",
    "    then function returns a dictionary such that your_unigram_counts[NOUN] == 275558.\n",
    "    \"\"\"\n",
    "    \n",
    "    unidict = {}\n",
    "    for i in range(len(sequences)):\n",
    "        for tag in sequences[i]:\n",
    "            if tag not in unidict.keys():\n",
    "                unidict[tag]=0\n",
    "            unidict[tag]+=1\n",
    "    \n",
    "    return unidict\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "tag_unigrams = unigram_counts(data.training_set.Y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADV': 44877, 'NOUN': 220632, '.': 117757, 'VERB': 146161, 'ADP': 115808, 'ADJ': 66754, 'CONJ': 30537, 'DET': 109671, 'PRT': 23906, 'NUM': 11878, 'PRON': 39383, 'X': 1094}\n"
     ]
    }
   ],
   "source": [
    "print(tag_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Counts\n",
    "\n",
    "Function below to estimates the co-occurrence frequency of each pair of symbols in each of the input sequences. These counts are used in the HMM model to estimate the bigram probability of two tags from the frequency counts according to the formula: $$P(tag_2|tag_1) = \\frac{C(tag_2|tag_1)}{C(tag_2)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your tag bigrams look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigram_counts(sequences):\n",
    "    \"\"\"Returns a dictionary keyed to each unique PAIR of values in the input sequences\n",
    "    list that counts the number of occurrences of pair in the sequences list. The input\n",
    "    should be a 2-dimensional array.\n",
    "    \n",
    "    For example, if the pair of tags (NOUN, VERB) appear 61582 times, then function\n",
    "    returns a dictionary such that your_bigram_counts[(NOUN, VERB)] == 61582\n",
    "    \"\"\"\n",
    "    bidict = {}\n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq)-1):\n",
    "            \n",
    "            if (seq[i],seq[i+1]) not in bidict.keys():\n",
    "                bidict[(seq[i],seq[i+1])] = 0\n",
    "            bidict[(seq[i],seq[i+1])] +=1\n",
    "\n",
    "    \n",
    "    return bidict               \n",
    "\n",
    "    \n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "tag_bigrams = bigram_counts(data.training_set.Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('ADV', 'NOUN'): 1478, ('NOUN', '.'): 62639, ('.', 'ADV'): 5124, ('ADV', '.'): 7577, ('.', 'VERB'): 9041, ('VERB', 'ADP'): 24927, ('ADP', 'ADJ'): 9533, ('ADJ', 'NOUN'): 43664, ('NOUN', 'CONJ'): 13185, ('CONJ', 'VERB'): 6012, ('VERB', 'ADJ'): 8423, ('.', 'DET'): 8008, ('DET', 'VERB'): 7062, ('ADJ', 'PRT'): 1301, ('PRT', 'ADP'): 2189, ('ADP', 'NUM'): 3467, ('NUM', 'NOUN'): 4524, ('.', 'PRON'): 5448, ('PRON', 'VERB'): 27860, ('VERB', 'PRT'): 9556, ('PRT', 'VERB'): 14886, ('VERB', 'NOUN'): 14230, ('NOUN', 'NUM'): 1783, ('NUM', '.'): 3210, ('.', 'NUM'): 1412, ('.', '.'): 12588, ('ADP', 'ADV'): 1805, ('ADV', 'NUM'): 597, ('DET', 'NOUN'): 68785, ('CONJ', 'DET'): 4636, ('NOUN', 'VERB'): 34972, ('ADP', 'NOUN'): 29965, ('ADP', 'DET'): 52841, ('NOUN', 'ADP'): 53884, ('CONJ', 'NOUN'): 7502, ('.', 'NOUN'): 9782, ('VERB', '.'): 11699, ('VERB', 'VERB'): 26957, ('.', 'ADP'): 7595, ('ADV', 'DET'): 3309, ('DET', 'ADJ'): 26236, ('NOUN', 'DET'): 3425, ('ADJ', '.'): 6666, ('VERB', 'DET'): 23764, ('ADJ', 'VERB'): 1167, ('NOUN', 'NOUN'): 32990, ('PRT', 'DET'): 2021, ('VERB', 'ADV'): 15076, ('ADV', 'CONJ'): 789, ('NOUN', 'ADJ'): 2839, ('DET', '.'): 1385, ('ADV', 'ADV'): 4336, ('ADV', 'ADJ'): 6143, ('ADJ', 'ADP'): 5895, ('ADP', 'PRON'): 8109, ('ADP', 'ADP'): 2347, ('NOUN', 'PRON'): 4369, ('ADV', 'PRT'): 1305, ('ADJ', 'ADJ'): 3758, ('.', 'ADJ'): 3334, ('ADJ', 'ADV'): 645, ('VERB', 'PRON'): 8001, ('PRON', '.'): 4078, ('.', 'CONJ'): 8174, ('CONJ', 'PRON'): 2058, ('DET', 'ADV'): 1937, ('ADV', 'VERB'): 10835, ('ADV', 'ADP'): 6352, ('CONJ', 'ADV'): 2759, ('VERB', 'CONJ'): 2105, ('ADP', 'VERB'): 4690, ('NOUN', 'ADV'): 5804, ('ADP', '.'): 1099, ('CONJ', 'ADJ'): 3372, ('VERB', 'NUM'): 1320, ('ADP', 'PRT'): 1675, ('PRON', 'DET'): 695, ('PRT', 'NUM'): 117, ('NUM', 'NUM'): 267, ('PRON', 'PRON'): 318, ('PRON', 'ADV'): 2099, ('DET', 'NUM'): 1073, ('PRON', 'ADP'): 2216, ('DET', 'PRON'): 1093, ('NUM', 'VERB'): 537, ('NUM', 'ADP'): 1559, ('.', 'PRT'): 2168, ('NOUN', 'PRT'): 3946, ('DET', 'ADP'): 978, ('ADV', 'PRON'): 2136, ('CONJ', 'ADP'): 2222, ('PRT', '.'): 1794, ('PRON', 'NOUN'): 340, ('ADJ', 'CONJ'): 2500, ('PRT', 'NOUN'): 845, ('ADP', 'CONJ'): 217, ('DET', 'DET'): 662, ('NUM', 'ADJ'): 705, ('DET', 'PRT'): 220, ('PRT', 'PRT'): 261, ('PRON', 'ADJ'): 359, ('PRON', 'PRT'): 919, ('PRON', 'CONJ'): 455, ('ADJ', 'PRON'): 249, ('PRT', 'ADV'): 866, ('PRT', 'PRON'): 166, ('PRT', 'CONJ'): 285, ('CONJ', 'PRT'): 760, ('CONJ', 'NUM'): 575, ('NUM', 'CONJ'): 442, ('PRT', 'ADJ'): 467, ('X', 'NOUN'): 58, ('NUM', 'ADV'): 234, ('NOUN', 'X'): 74, ('X', 'PRON'): 9, ('NUM', 'PRON'): 109, ('ADJ', 'NUM'): 467, ('NUM', 'DET'): 156, ('CONJ', '.'): 612, ('X', 'X'): 552, ('X', 'VERB'): 62, ('DET', 'X'): 156, ('PRON', 'NUM'): 39, ('DET', 'CONJ'): 70, ('X', 'CONJ'): 24, ('X', 'ADP'): 61, ('X', 'DET'): 5, ('X', '.'): 303, ('ADJ', 'DET'): 386, ('.', 'X'): 147, ('ADP', 'X'): 53, ('CONJ', 'X'): 18, ('ADJ', 'X'): 31, ('NUM', 'PRT'): 69, ('VERB', 'X'): 28, ('X', 'ADV'): 7, ('ADV', 'X'): 4, ('X', 'PRT'): 8, ('NUM', 'X'): 3, ('PRT', 'X'): 2, ('CONJ', 'CONJ'): 9, ('X', 'ADJ'): 3, ('X', 'NUM'): 1, ('PRON', 'X'): 1}\n"
     ]
    }
   ],
   "source": [
    "print(tag_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Starting Counts\n",
    "Functions below to estimates the bigram probabilities of a sequence starting with each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your starting tag counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def starting_counts(sequences):\n",
    "    \"\"\"Returns a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the beginning of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 8093 sequences start with NOUN, then function returns a\n",
    "    dictionary such that your_starting_counts[NOUN] == 8093\n",
    "    \"\"\"\n",
    "    \n",
    "    startcount_dict = {}\n",
    "    for seq in sequences:\n",
    "        if seq[0] not in startcount_dict:\n",
    "            startcount_dict[seq[0]]=0\n",
    "        startcount_dict[seq[0]]+=1\n",
    "    return startcount_dict\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "tag_starts = starting_counts(data.training_set.Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADV': 4185, 'ADP': 5583, 'ADJ': 1582, 'PRT': 1718, 'DET': 9763, 'PRON': 7318, 'NOUN': 6469, 'CONJ': 2282, '.': 4107, 'NUM': 760, 'VERB': 2080, 'X': 25}\n"
     ]
    }
   ],
   "source": [
    "print(tag_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Ending Counts\n",
    "Function below to estimates the bigram probabilities of a sequence ending with each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your ending tag counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ending_counts(sequences):\n",
    "    \"\"\"Returns a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the end of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 18 sequences end with DET, then function returns a\n",
    "    dictionary such that ending_counts[DET] == 18\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    endcount_dict = {}\n",
    "    for seq in sequences:\n",
    "        if seq[-1] not in endcount_dict:\n",
    "            endcount_dict[seq[-1]]=0\n",
    "        endcount_dict[seq[-1]]+=1\n",
    "    return endcount_dict\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "tag_ends = ending_counts(data.training_set.Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 44936, 'NOUN': 722, 'NUM': 63, 'VERB': 75, 'ADJ': 25, 'ADV': 16, 'ADP': 7, 'DET': 14, 'CONJ': 2, 'PRON': 4, 'PRT': 7, 'X': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tag_ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic HMM Tagger\n",
    "The unigrams and bigrams calculated is used to construct a hidden Markov tagger.\n",
    "\n",
    "- Add one state per tag\n",
    "    - The emission distribution at each state should be estimated with the formula: $P(w|t) = \\frac{C(t, w)}{C(t)}$\n",
    "- Add an edge from the starting state `basic_model.start` to each tag\n",
    "    - The transition probability should be estimated with the formula: $P(t|start) = \\frac{C(start, t)}{C(start)}$\n",
    "- Add an edge from each tag to the end state `basic_model.end`\n",
    "    - The transition probability should be estimated with the formula: $P(end|t) = \\frac{C(t, end)}{C(t)}$\n",
    "- Add an edge between _every_ pair of tags\n",
    "    - The transition probability should be estimated with the formula: $P(t_2|t_1) = \\frac{C(t_1, t_2)}{C(t_1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n",
    "basic_model.states = []\n",
    "\n",
    "\n",
    "state_dict = {}\n",
    "\n",
    "traintags, trainwords = [], []\n",
    "\n",
    "for pair in data.stream():\n",
    "    traintags.append(pair[1])\n",
    "    trainwords.append(pair[0])\n",
    "\n",
    "emission_probabilities_all = pair_counts(traintags, trainwords)\n",
    "\n",
    "for tag in data.training_set.tagset:\n",
    "    emission_probabilities = emission_probabilities_all[tag]\n",
    "    for word in emission_probabilities:\n",
    "        emission_probabilities[word] = emission_probabilities[word] / tag_unigrams[tag]\n",
    "    emission_distribution = DiscreteDistribution(emission_probabilities)\n",
    "    state = State(emission_distribution, name=tag)\n",
    "    state_dict[tag]=state\n",
    "    basic_model.states.append(state)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for tag in data.training_set.tagset:\n",
    "    tag_starts[tag] = tag_starts[tag]/len(data.training_set.Y)\n",
    "      \n",
    "    tag_ends[tag] = tag_ends[tag]/len(data.training_set.Y) \n",
    "\n",
    "for tag in data.training_set.tagset:\n",
    "    basic_model.add_transition(basic_model.start, state_dict[tag], tag_starts[tag])\n",
    "    basic_model.add_transition(state_dict[tag], basic_model.end, tag_ends[tag])\n",
    "\n",
    "\n",
    "\n",
    "for tag1 in data.training_set.tagset:\n",
    "    for tag2 in data.training_set.tagset:\n",
    "        transition_prob = tag_bigrams[(tag1, tag2)] / tag_unigrams[tag1]\n",
    "        basic_model.add_transition(state_dict[tag1], state_dict[tag2], transition_prob)\n",
    "\n",
    "\n",
    "basic_model.bake()        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy basic hmm model: 97.54%\n",
      "testing accuracy basic hmm model: 96.18%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your HMM tagger accuracy looks correct! Congratulations, you've finished the project.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
    "print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n",
    "\n",
    "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
    "print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Decoding Sequences with the HMM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, basic_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
